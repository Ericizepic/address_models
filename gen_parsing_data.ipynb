{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address Parsing Synthetic Data Generation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The following script was used to generate data used to finetune the deepparse library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the follow packages\n",
    "# !pip install Faker==23.1.0 nlpaug==1.1.11 numpy==1.26.4 pandas==2.0.3 tqdm==4.66.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import string\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from faker import Faker\n",
    "from typing import List \n",
    "from numpy.random import choice\n",
    "from numpy.testing import assert_almost_equal\n",
    "from string import ascii_lowercase, digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "The following dictionaries contains abbreviations and equivalences. to_non_stand_X maps a standard term to a non standard equivalent term. to_stand builds the inverse map. TODO: Add more elements to to_non_stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_dir_en = [\n",
    "    \"e\", \"east\", \"e.\",\n",
    "    \"n\", \"north\", \"n.\", \"nrt\", \"nrth\", \"northern\",\n",
    "    \"ne\",\n",
    "        \"northeast\",\n",
    "        \"north east\",\n",
    "        \"northe\",\n",
    "        \"north e\",\n",
    "        \"neast\",\n",
    "        \"n east\",\n",
    "        \"ne\",\n",
    "        \"n e\",\n",
    "        \"nrteast\",\n",
    "        \"nrt east\",\n",
    "        \"nrte\",\n",
    "        \"nrt e\",\n",
    "        \"nrtheast\",\n",
    "        \"nrth east\",\n",
    "        \"nrthe\",\n",
    "        \"nrth e\",\n",
    "        \"ntheast\",\n",
    "        \"nth east\",\n",
    "        \"nthe\",\n",
    "        \"nth e\",\n",
    "        \"norheast\",\n",
    "        \"norh east\",\n",
    "        \"norhe\",\n",
    "        \"norh e\",\n",
    "        \"norteast\",\n",
    "        \"nort east\",\n",
    "        \"norte\",\n",
    "        \"nort e\",\n",
    "    \"nw\",\n",
    "        \"northwest\",\n",
    "        \"north west\",\n",
    "        \"northw\",\n",
    "        \"north w\",\n",
    "        \"northwst\",\n",
    "        \"north wst\",\n",
    "        \"nwest\",\n",
    "        \"n west\",\n",
    "        \"n w\",\n",
    "        \"nwst\",\n",
    "        \"n wst\",\n",
    "        \"nrtwest\",\n",
    "        \"nrt west\",\n",
    "        \"nrtw\",\n",
    "        \"nrt w\",\n",
    "        \"nrtwst\",\n",
    "        \"nrt wst\",\n",
    "        \"nrthwest\",\n",
    "        \"nrth west\",\n",
    "        \"nrthw\",\n",
    "        \"nrth w\",\n",
    "        \"nrthwst\",\n",
    "        \"nrth wst\",\n",
    "        \"nthwest\",\n",
    "        \"nth west\",\n",
    "        \"nthw\",\n",
    "        \"nth w\",\n",
    "        \"nthwst\",\n",
    "        \"nth wst\",\n",
    "        \"norhwest\",\n",
    "        \"norh west\",\n",
    "        \"norhw\",\n",
    "        \"norh w\",\n",
    "        \"norhwst\",\n",
    "        \"norh wst\",\n",
    "        \"nortwest\",\n",
    "        \"nort west\",\n",
    "        \"nortw\",\n",
    "        \"nort w\",\n",
    "        \"nortwst\",\n",
    "        \"nort wst\",\n",
    "    \"s\", \"south\", \"so\", \"sth\",\n",
    "    \"se\",\n",
    "        \"southeast\",\n",
    "        \"south east\",\n",
    "        \"southe\",\n",
    "        \"south e\",\n",
    "        \"seast\",\n",
    "        \"s east\",\n",
    "        \"s e\",\n",
    "        \"soeast\",\n",
    "        \"so east\",\n",
    "        \"so e\",\n",
    "        \"stheast\",\n",
    "        \"sth east\",\n",
    "        \"sthe\",\n",
    "        \"sth e\",\n",
    "    \"sw\",\n",
    "        \"southwest\",\n",
    "        \"south west\",\n",
    "        \"southw\",\n",
    "        \"south w\",\n",
    "        \"southwst\",\n",
    "        \"south wst\",\n",
    "        \"swest\",\n",
    "        \"s west\",\n",
    "        \"s w\",\n",
    "        \"swst\",\n",
    "        \"s wst\",\n",
    "        \"sowest\",\n",
    "        \"so west\",\n",
    "        \"so w\",\n",
    "        \"sowst\",\n",
    "        \"so wst\",\n",
    "        \"sthwest\",\n",
    "        \"sth west\",\n",
    "        \"sthw\",\n",
    "        \"sth w\",\n",
    "        \"sthwst\",\n",
    "        \"sth wst\",\n",
    "    \"w\", \"west\", \"wst\",\n",
    "]\n",
    "\n",
    "street_dir_fr = [\n",
    "    \"e\", \"est\", \"e.\",\n",
    "    \"n\", \"nord\", \"n.\",\n",
    "    \"ne\",\n",
    "        \"nord-est\",\n",
    "    \"nw\",\n",
    "        \"nord ouest\"\n",
    "    \"s\", \"sud\",\n",
    "    \"se\",\n",
    "        \"sud-est\",\n",
    "    \"sw\",\n",
    "        \"sud ouest\",\n",
    "    \"w\", \"ouest\",\n",
    "]\n",
    "\n",
    "province_lst = [\"on\", \"ab\", \"bc\", \"ns\", \"nb\", \"pe\", \"qc\", \"sk\", \"mb\", \"nt\"]\n",
    "\n",
    "to_non_stand_prov = {\n",
    "    \"ab\": [\"alberta\"],\n",
    "    \"bc\": [\"british columbia\", \"b.c.\", \"b. c.\"],\n",
    "    \"mb\": [\"manitoba\"],\n",
    "    \"nb\": [\"new brunswick\", \"n.b.\"],\n",
    "    \"ns\": [\"nova scotia\", \"n.s.\", \"n. s.\"],\n",
    "    \"nt\": [\"northwest territories\", \"n.t.\", \"nwt\"],\n",
    "    \"nu\": [\"nunavut\"],\n",
    "    \"on\": [\"ontario\"],\n",
    "    \"pe\": [\"prince edward island\", \"pei\", \"p. e. i.\", \"p.e.i\"],\n",
    "    \"qc\": [\"quebec\"],\n",
    "    \"sk\": [\"saskatchewan\"],\n",
    "    \"yt\": [\"yukon\", \"the yukon\", \"yukon territory\"],\n",
    "    \"nl\": [\"newfoundland and labrador\", \"n. l.\", \"n.l.\"],\n",
    "}\n",
    "\n",
    "to_non_stand_street_dir = {\n",
    "    \"e\": [\"east\", \"e.\"],\n",
    "    \"n\": [\"north\", \"n.\", \"nrt\", \"nrth\", \"northern\"],\n",
    "    \"ne\": [\n",
    "        \"northeast\",\n",
    "        \"north east\",\n",
    "        \"northe\",\n",
    "        \"north e\",\n",
    "        \"neast\",\n",
    "        \"n east\",\n",
    "        \"ne\",\n",
    "        \"n e\",\n",
    "        \"nrteast\",\n",
    "        \"nrt east\",\n",
    "        \"nrte\",\n",
    "        \"nrt e\",\n",
    "        \"nrtheast\",\n",
    "        \"nrth east\",\n",
    "        \"nrthe\",\n",
    "        \"nrth e\",\n",
    "        \"ntheast\",\n",
    "        \"nth east\",\n",
    "        \"nthe\",\n",
    "        \"nth e\",\n",
    "        \"norheast\",\n",
    "        \"norh east\",\n",
    "        \"norhe\",\n",
    "        \"norh e\",\n",
    "        \"norteast\",\n",
    "        \"nort east\",\n",
    "        \"norte\",\n",
    "        \"nort e\",\n",
    "    ],\n",
    "    \"nw\": [\n",
    "        \"northwest\",\n",
    "        \"north west\",\n",
    "        \"northw\",\n",
    "        \"north w\",\n",
    "        \"northwst\",\n",
    "        \"north wst\",\n",
    "        \"nwest\",\n",
    "        \"n west\",\n",
    "        \"n w\",\n",
    "        \"nwst\",\n",
    "        \"n wst\",\n",
    "        \"nrtwest\",\n",
    "        \"nrt west\",\n",
    "        \"nrtw\",\n",
    "        \"nrt w\",\n",
    "        \"nrtwst\",\n",
    "        \"nrt wst\",\n",
    "        \"nrthwest\",\n",
    "        \"nrth west\",\n",
    "        \"nrthw\",\n",
    "        \"nrth w\",\n",
    "        \"nrthwst\",\n",
    "        \"nrth wst\",\n",
    "        \"nthwest\",\n",
    "        \"nth west\",\n",
    "        \"nthw\",\n",
    "        \"nth w\",\n",
    "        \"nthwst\",\n",
    "        \"nth wst\",\n",
    "        \"norhwest\",\n",
    "        \"norh west\",\n",
    "        \"norhw\",\n",
    "        \"norh w\",\n",
    "        \"norhwst\",\n",
    "        \"norh wst\",\n",
    "        \"nortwest\",\n",
    "        \"nort west\",\n",
    "        \"nortw\",\n",
    "        \"nort w\",\n",
    "        \"nortwst\",\n",
    "        \"nort wst\",\n",
    "    ],\n",
    "    \"s\": [\"south\", \"so\", \"sth\"],\n",
    "    \"se\": [\n",
    "        \"southeast\",\n",
    "        \"south east\",\n",
    "        \"southe\",\n",
    "        \"south e\",\n",
    "        \"seast\",\n",
    "        \"s east\",\n",
    "        \"s e\",\n",
    "        \"soeast\",\n",
    "        \"so east\",\n",
    "        \"so e\",\n",
    "        \"stheast\",\n",
    "        \"sth east\",\n",
    "        \"sthe\",\n",
    "        \"sth e\",\n",
    "    ],\n",
    "    \"sw\": [\n",
    "        \"southwest\",\n",
    "        \"south west\",\n",
    "        \"southw\",\n",
    "        \"south w\",\n",
    "        \"southwst\",\n",
    "        \"south wst\",\n",
    "        \"swest\",\n",
    "        \"s west\",\n",
    "        \"s w\",\n",
    "        \"swst\",\n",
    "        \"s wst\",\n",
    "        \"sowest\",\n",
    "        \"so west\",\n",
    "        \"so w\",\n",
    "        \"sowst\",\n",
    "        \"so wst\",\n",
    "        \"sthwest\",\n",
    "        \"sth west\",\n",
    "        \"sthw\",\n",
    "        \"sth w\",\n",
    "        \"sthwst\",\n",
    "        \"sth wst\",\n",
    "    ],\n",
    "    \"w\": [\"west\", \"wst\"],\n",
    "}\n",
    "\n",
    "to_non_stand_num_term = {\n",
    "    \"unit\": [\n",
    "        \"suite\",\n",
    "        \"apt\",\n",
    "        \"apartment\",\n",
    "        \"ste\",\n",
    "    ],  # unit is special case stuff like 123-43 king should eval to unit 123 43 king\n",
    "    \"po box\": [\n",
    "        \"post office box\",\n",
    "        \"p.o. box\",\n",
    "        \"p.o box\",\n",
    "        \"pobox\",\n",
    "        \"postbox\",\n",
    "        \"post box\",\n",
    "        \"post box\",\n",
    "        \"p o box\",\n",
    "        \"p office box\",\n",
    "        \"pb\",\n",
    "        \"pob\",\n",
    "        \"p o b\",\n",
    "        \"post mail box\",\n",
    "        \"post mail box\",\n",
    "        \"pmb\",\n",
    "        \"box\",\n",
    "        \"box\",\n",
    "        \"box\",\n",
    "    ],\n",
    "    \"ph\" : [\n",
    "        \"penthouse\",\n",
    "        \"pent house\",\n",
    "        \"penth\",\n",
    "        \"penthse\",\n",
    "        \"pHouse\",\n",
    "        \"pent.\",\n",
    "        \"ph\",\n",
    "    ],\n",
    "    \"rr\" : [\"rr#\", \"rural road\", \"r road\", \"country road\", \"side road\"]\n",
    "}\n",
    "\n",
    "to_non_stand_street_type = {\n",
    "    \"alley\": [\"aly\", \"ally\"],\n",
    "    \"alwy\": [\"alleyway\", \"allyway\", \"allwy\"],\n",
    "    \"anx\": [\"annex\", \"anex\", \"annx\"],\n",
    "    \"arc\": [\"arcade\"],\n",
    "    \"ave\": [\"avenue\", \"av\", \"aven\", \"avenu\", \"avn\", \"avnue\"],\n",
    "    \"bayou\": [\"bayoo\"],\n",
    "    \"bch\": [\"beach\"],\n",
    "    \"bldg\": [\"building\", \"bdg\", \"bld\", \"blg\"],\n",
    "    \"blf\": [\"bluf\", \"bluff\"],\n",
    "    \"blfs\": [\"bluffs\"],\n",
    "    \"blk\": [\"block\"],\n",
    "    \"blvd\": [\"boulevard\", \"boul\", \"boulv\"],\n",
    "    \"bnd\": [\"bend\"],\n",
    "    \"bnglw\": [\"bungalow\", \"bongalow\", \"bunglow\", \"bungalo\", \"bngw\"],\n",
    "    \"bot\": [\"bottom\", \"bottm\", \"btm\"],\n",
    "    \"br\": [\"branch\", \"brnch\"],\n",
    "    \"brg\": [\"bridge\", \"brdge\"],\n",
    "    \"brgs\": [\"burgs\"],\n",
    "    \"brk\": [\"brook\", \"break\"],\n",
    "    \"brks\": [\"brooks\"],\n",
    "    \"bsmt\": [\"basement\", \"bsm\", \"bsmnt\", \"basement\", \"bsment\"],\n",
    "    \"byps\": [\"bypass\", \"bypa\", \"bps\", \"byp\"],\n",
    "    \"cabin\": [\"cabn\"],\n",
    "    \"circ\": [\"circle\", \"cir\", \"circel\", \"circles\"],\n",
    "    \"clf\": [\"cliff\"],\n",
    "    \"clfs\": [\"cliffs\"],\n",
    "    \"cmn\": [\"common\"],\n",
    "    \"cmns\": [\"commons\"],\n",
    "    \"cmp\" : [\"camp\"],\n",
    "    \"cnyn\" : [\"canyon\", \"cyn\"],\n",
    "    \"cor\" : [\"corner\"],\n",
    "    \"cors\" : [\"corners\"],\n",
    "    \"cpe\": [\"cape\"],\n",
    "    \"cresc\": [\"crescent\", \"crs\", \"crecent\"],\n",
    "    \"crk\": [\"creek\"],\n",
    "    \"crossing\": [\"xing\", \"crssing\"],\n",
    "    \"crossroad\" : [\"cross road\", \"xroad\"],\n",
    "    \"cswy\": [\"causeway\", \"cause way\"],\n",
    "    \"ct\" : [\"court\"],\n",
    "    \"ctyd\" : [\"court yard\", \"courtyard\"],\n",
    "    \"ctr\": [\"center\", \"centre\", \"cent\", \"centr\", \"cnter\", \"cntr\"],\n",
    "    \"curv\" : [\"curve\"],\n",
    "    \"cv\" : [\"cove\"],\n",
    "    \"cvs\" : [\"coves\"],\n",
    "    \"dl\" : [\"dale\"],\n",
    "    \"dm\" : [\"dam\"],\n",
    "    \"div\" : [\"divide\"],\n",
    "    \"dr\": [\"drive\", \"drv\", \"driv\"],\n",
    "    \"drs\" : [\"drives\"],\n",
    "    \"dupl\": [\"duplex\", \"dup\"],\n",
    "    \"dvwy\": [\"driveway\", \"dway\", \"drive way\"],\n",
    "    \"est\": [\"estate\"],\n",
    "    \"ests\" : [\"estates\"],\n",
    "    \"exp\": [\"express\", \"expressway\", \"express way\", \"expwy\", \"expw\", \"expr\"],\n",
    "    \"fcty\": [\"fty\", \"fy\"],\n",
    "    \"fl\": [\n",
    "        \"floor\",\n",
    "        \"flr\",\n",
    "        \"f\",\n",
    "        \"level\",\n",
    "        \"lev\",\n",
    "        \"levl\",\n",
    "        \"lvel\",\n",
    "        \"lvl\",\n",
    "        \"platform\",\n",
    "        \"pf\",\n",
    "        \"storey\",\n",
    "    ],\n",
    "    \"fld\": [\"field\"],\n",
    "    \"flds\" : [\"fields\"],\n",
    "    \"fls\" : [\"falls\"],\n",
    "    \"flt\": [\"flat\"],\n",
    "    \"frd\": [\"ford\"],\n",
    "    \"frds\" : [\"fords\"],\n",
    "    \"frg\" : [\"forge\", \"forg\"],\n",
    "    \"frgs\" : [\"forges\"],\n",
    "    \"frk\": [\"fork\"],\n",
    "    \"frst\": [\"forest\"],\n",
    "    \"fry\": [\"ferry\", \"frry\"],\n",
    "    \"fwy\": [\"freeway\", \"free way\", \"freewy\"],\n",
    "    \"gdfl\": [\n",
    "        \"ground floor\",\n",
    "        \"gdfl\",\n",
    "        \"gd fl\",\n",
    "        \"gd/fl\",\n",
    "        \"gd / fl\",\n",
    "        \"gf\",\n",
    "        \"ground level\",\n",
    "        \"gd lvl\",\n",
    "        \"g lvl\",\n",
    "        \"g level\",\n",
    "        \"gd level\",\n",
    "        \"ground lvl\",\n",
    "        \"lobby\",\n",
    "        \"main floor\",\n",
    "    ],\n",
    "    \"gpo\": [\"general post office box\", \"gpo box\"],\n",
    "    \"grdn\": [\"garden\", \"gardn\"],\n",
    "    \"grn\" : [\"green\"],\n",
    "    \"grns\" : [\"greens\"],\n",
    "    \"grv\": [\"grove\", \"grov\"],\n",
    "    \"grvs\": [\"groves\"],\n",
    "    \"gym\": [\"gymnasium\"],\n",
    "    \"hbr\" : [\"harbour\", \"hrbor\"],\n",
    "    \"hbrs\" : [\"harbours\"],\n",
    "    \"hl\": [\"hill\"],\n",
    "    \"hls\" : [\"hills\"],\n",
    "    \"hllw\": [\"hollow\", \"holw\"],\n",
    "    \"hotl\": [\"hotel\", \"hot\", \"htel\"],\n",
    "    \"hs\": [\"high school\", \"h s\"],\n",
    "    \"hsp\": [\"hospital\", \"hos\", \"hosp\", \"hospice\", \"hosptl\", \"hsptl\"],\n",
    "    \"hts\": [\"heights\"],\n",
    "    \"hvn\": [\"haven\"],\n",
    "    \"hwy\": [\"highway\", \"highwy\"],\n",
    "    \"jct\": [\"junction\", \"jction\", \"juncton\"],\n",
    "    \"jcts\": [\"junctions\"],\n",
    "    \"ky\" : [\"key\"],\n",
    "    \"kys\" : [\"keys\"],\n",
    "    \"knl\" : [\"knoll\"],\n",
    "    \"knls\" : [\"knolls\"],\n",
    "    \"lck\": [\"lock\"],\n",
    "    \"lcks\": [\"locks\"],\n",
    "    \"ldg\": [\"lodge\", \"lodg\", \"ldge\"],\n",
    "    \"lgt\": [\"light\"],\n",
    "    \"lk\" : [\"lake\"],\n",
    "    \"lks\" : [\"lakes\"],\n",
    "    \"ln\": [\"lane\"],\n",
    "    \"lp\": [\"loop\"],\n",
    "    \"lwr\": [\"lower\", \"lowr\"],\n",
    "    \"mdw\": [\"meadow\"],\n",
    "    \"mdws\" : [\"meadows\"],\n",
    "    \"ml\" : [\"mill\"],\n",
    "    \"mls\" : [\"mills\"],\n",
    "    \"mnr\": [\"manor\"],\n",
    "    \"mnrs\" : [\"manors\"],\n",
    "    \"msn\" : [\"mission\"],\n",
    "    \"mt\": [\"mount\"],\n",
    "    \"mtn\": [\"mountain\"],\n",
    "    \"mtns\": [\"mountains\"],\n",
    "    \"mtwy\": [\"motorway\", \"motor way\"],\n",
    "    \"nck\" : [\"neck\"],\n",
    "    \"orch\": [\"orchard\", \"orchrd\"],\n",
    "    \"ovl\": [\"oval\"],\n",
    "    \"ovlk\" : [\"overlook\", \"over look\"],\n",
    "    \"opas\" :  [\"overpass\",\"over pass\"],\n",
    "    \"pkwy\": [\"parkway\", \"parkwy\", \"pkway\", \"prkwy\", \"prkway\", \"park way\"],\n",
    "    \"pl\": [\"place\", \"pla\", \"plc\", \"plac\"],\n",
    "    \"plz\": [\"plaza\", \"plza\"],\n",
    "    \"prk\": [\"park\"],\n",
    "    \"prt\": [\"port\"],\n",
    "    \"psge\" : [\"passage\"],\n",
    "    \"pt\": [\"point\"],\n",
    "    \"pts\": [\"points\"],\n",
    "    \"pth\": [\"path\"],\n",
    "    \"pthwy\": [\"phwy\",\"pway\",\"pthway\",\"pathway\",\"ptway\",\"ptwy\", \"pathwy\"],\n",
    "    \"rd\": [\"road\"],\n",
    "    \"rds\" : [\"roads\"],\n",
    "    \"rdg\": [\"ridge\", \"rdge\"],\n",
    "    \"rnch\": [\"ranch\"],\n",
    "    \"rte\": [\"route\"],\n",
    "    \"rvr\": [\"river\", \"riv\", \"rivr\"],\n",
    "    \"skwy\": [\"skyway\", \"sky way\"],\n",
    "    \"smt\": [\"summit\"],\n",
    "    \"spg\": [\"spring\", \"sprng\", \"spng\"],\n",
    "    \"spgs\": [\"springs\"],\n",
    "    \"sq\": [\"square\", \"sqr\"],\n",
    "    \"st\" : [\"str\",\"stre\",\"stree\",\"strt\", \"street\", \"streets\"],\n",
    "    \"stn\": [\"station\", \"statn\", \"sta\"],\n",
    "    \"tce\": [\"terrace\", \"ter\", \"tr\", \"terr\", \"terace\", \"terrac\", \"terrasse\", \"tsse\"],\n",
    "    \"tpke\": [\"turnpike\", \"trnpk\", \"turnpk\"],\n",
    "    \"trfy\": [\"trafficway\"],\n",
    "    \"trl\": [\"trail\"],\n",
    "    \"trwy\": [\"throughway\", \"through way\"],\n",
    "    \"twr\": [\"tower\", \"towers\"],\n",
    "    \"u\": [\"university\", \"uni\", \"univ\", \"univers\", \"unvrsty\"],\n",
    "    \"un\": [\"union\"],\n",
    "    \"upas\": [\"underpass\"],\n",
    "    \"upr\": [\"upper\", \"uppr\", \"up\"],\n",
    "    \"vdct\": [\"viaduct\", \"viadct\"],\n",
    "    \"vis\": [\"vista\", \"vst\", \"vsta\", \"vist\"],\n",
    "    \"vl\": [\"ville\"],\n",
    "    \"vlg\": [\"village\", \"vge\", \"vllg\"],\n",
    "    \"vly\": [\"valley\", \"vallys\", \"vlly\"],\n",
    "    \"vlys\": [\"valleys\"],\n",
    "    \"wl\" : [\"wells\"],\n",
    "    \"wy\": [\"way\"],\n",
    "}\n",
    "\n",
    "to_non_std = {\n",
    "    \"st\": [\"saint\", \"st.\"],\n",
    "    \"1st\" : [\"first\"],\n",
    "    \"2nd\" : [\"second\"],\n",
    "    \"3rd\" : [\"third\"],\n",
    "    \"4th\" : [\"fourth\"],\n",
    "    \"5th\" : [\"fifth\"],\n",
    "    \"6th\" : [\"sixth\"],\n",
    "    \"7th\" : [\"seventh\"],\n",
    "    \"8th\" : [\"eighth\"],\n",
    "    \"9th\" : [\"ninth\"],\n",
    "}\n",
    "\n",
    "to_stand_street_type = {i: k for k, v in to_non_stand_street_type.items() for i in v}\n",
    "to_stand_street_dir = {i: k for k, v in to_non_stand_street_dir.items() for i in v}\n",
    "to_std = {i : k for k,v in to_non_std.items() for i in v}\n",
    "\n",
    "street_type = list(to_non_stand_street_type.keys())\n",
    "street_dir = list(to_non_stand_street_dir.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(p: float) -> bool:\n",
    "    \"Returns true with probability p\"\n",
    "    \n",
    "    return rand.uniform(0, 1) < p\n",
    "\n",
    "\n",
    "def insert_spaces(s: string, p:float)->string:\n",
    "    \"Returns s with space inserted between adjacent characters with prob p\"\n",
    "\n",
    "    s = list(s)\n",
    "    for i in range(len(s)-1):\n",
    "        if prob(p):\n",
    "            s[i] = s[i] + ' '\n",
    "    return ''.join(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions take in a string and performs synthetic OCR augments on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_split = naw.SplitAug(min_char=3) #augments string by splitting it\n",
    "conf_matrix = pd.read_csv(\"ocr_confusion_matrix.csv\", index_col=0) #conf matrix gives prob that a letter is augmented to another letter\n",
    "conf_matrix_num_to_letter = pd.read_csv(\"ocr_confusion_matrix_num_to_letter.csv\", index_col=0) #conf matrix gives prob that a letter is augmented to another letter, num can only become a num\n",
    "\n",
    "def pc_augment(pc : str, letter_aug = 0.1, num_aug = 0.2) -> str:  \n",
    "    \"\"\"\n",
    "    pc - postal code\n",
    "    Used to augment postal code terms. For each char in pc, modify each letter with prob letter_aug and each digit with prog num_aug\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\".join([c if c not in conf_matrix_num_to_letter.columns or (c.isdigit() and prob(1 - num_aug)) or (not c.isdigit() and prob(1 - letter_aug)) else rand.choices(conf_matrix_num_to_letter.columns, weights=conf_matrix_num_to_letter.loc[c], k = 1)[0] for c in pc])\n",
    "\n",
    "\n",
    "def num_augment(s : str, letter_aug = 0.05, num_aug = 0.05) -> str:\n",
    "    \"\"\"\n",
    "    s - num\n",
    "    Used to augment num terms (street numbers, units). For each char in s, modify each letter with prob letter_aug and each digit with prog num_aug    \n",
    "    \"\"\"\n",
    "\n",
    "    return \"\".join([c if c not in conf_matrix_num_to_letter.columns or (c.isdigit() and prob(num_aug)) or (not c.isdigit() and prob(letter_aug)) else rand.choices(conf_matrix_num_to_letter.columns, weights=conf_matrix_num_to_letter.loc[c], k = 1)[0] for c in s ])\n",
    "\n",
    "\n",
    "def rm_space_augment(s : str, keep_ws_p = 0.9) -> str:\n",
    "    \"Returns s with every whitespace being kept with prob keep_ws_p\"\n",
    "\n",
    "    return \"\".join([w for w in s if w not in string.whitespace or prob(keep_ws_p)])\n",
    "\n",
    "\n",
    "def augment(s : str, letter_aug = 0.85, num_aug = 0.98, keep_p = 1) -> str:\n",
    "    \"\"\"\n",
    "    s - string\n",
    "    Used to augment general strings. For each char in s, modify each letter with prob letter_aug and each digit with prog num_aug    \n",
    "    \"\"\"\n",
    "\n",
    "    return \"\".join([c if c not in conf_matrix.columns or (c.isdigit() and prob(num_aug) or (not c.isdigit() and prob(letter_aug))) else choice(conf_matrix.columns, p=conf_matrix.loc[c]) for c in s if prob(keep_p)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions generate synthetic address terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_en = Faker(\"en_CA\") # init faker library for english canadian address terms\n",
    "fake_fr = Faker(\"fr_CA\") # init faker library for french canadian address terms\n",
    "\n",
    "SUFFIXES = {1: \"st\", 2: \"nd\", 3: \"rd\"}\n",
    "\n",
    "def rand_ordinal_street():\n",
    "    \"returns a random ordinal street address\"\n",
    "\n",
    "    num = rand.randint(1, 120)\n",
    "    suffix = \"th\" if 10 <= num % 100 <= 20 else SUFFIXES.get(num % 10, \"th\")\n",
    "    if prob(0.3):\n",
    "        return str(num)\n",
    "    \n",
    "    return str(num) + suffix\n",
    "\n",
    "\n",
    "def rand_unit_num():\n",
    "    \"returns a random unit term\"\n",
    "\n",
    "    options = [f\"{rand.randint(1, 120)}\", f\"{rand.randint(1, 9999)}\", f\"{rand.randint(1, 9999)}{rand.choice(ascii_lowercase)}\"] \n",
    "    return choice(options, p=[0.5, 0.35, 0.15])\n",
    "\n",
    "def rand_rr():\n",
    "    \"returns a random rural road term\"\n",
    "\n",
    "    rroptions = [f\"rr {rand.randint(1, 120)}\", f\"rr{rand.randint(1, 120)}\"]\n",
    "    return rand.choice(rroptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen_parsed_tags is the main driver function which takes in the raw address data and returns an address as well as the tags of each word in the address (address, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insertion_index(tags: List[str]):\n",
    "    \"\"\"\n",
    "    tags - list of address tags (eg. [\"street_no\", \"street_name\", \"postal_code\"])\n",
    "    returns a random valid index which we could insert another address term. We dont want to insert in between certain terms like streetnumber and street name it would fundamentally change the address\n",
    "    \"\"\"\n",
    "    insertable_indices = [0, len(tags)]\n",
    "    for i in range(1, len(tags)):\n",
    "        if tags[i][:5] != tags[i - 1][:5]:\n",
    "            insertable_indices.append(i)\n",
    "\n",
    "    return rand.choice(insertable_indices)\n",
    "\n",
    "\n",
    "def gen_parsed_tags(wt : List[str], tt: List[str], is_en = True) -> tuple[str, ...]:\n",
    "    \"\"\"\n",
    "    wt (word terms) - list of address terms (eg. [\"76\", \"abc\", \"street\"])\n",
    "    tt (tags terms) - the address tag for each address term in wt (eg. [\"street_no\", \"street_name\", \"street_name\"] for [\"76\", \"abc\", \"street\"])\n",
    "    is_en - whether the address is french or english\n",
    "\n",
    "    returns a pair, an address as well as the tags of each word in the address. The trained deepparse should parse the address as the tags\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(wt) == len(tt)\n",
    "\n",
    "    # perform rearrangments on wt, tt. Want to mix up ordering of address terms since not all addresses come in the same order. wt and tt must undergo the same rearrangment.\n",
    "    r = rand.uniform(0,1)\n",
    "    if r < 0.1:\n",
    "        str_wt, str_tt = [], []\n",
    "        nstr_wt, nstr_tt = [], []\n",
    "\n",
    "        # We take out street info (street_no, street_name, street_dir), unit info and pobox info as their relative order must be preserved\n",
    "        for i in range(len(wt)):\n",
    "            if tt[i][:3] == \"str\" or tt[i] == \"unit\" or tt[i] == \"pobox\":\n",
    "                str_wt.append(wt[i])\n",
    "                str_tt.append(tt[i])\n",
    "            else:\n",
    "                nstr_wt.append(wt[i])\n",
    "                nstr_tt.append(tt[i])\n",
    "        \n",
    "        # Randomly shuffle the remaining terms\n",
    "        msk = list(range(len(nstr_wt)))\n",
    "        rand.shuffle(msk)\n",
    "        wt = [nstr_wt[i] for i in msk]\n",
    "        tt = [nstr_tt[i] for i in msk]\n",
    "\n",
    "        # Insert removed terms back in\n",
    "        iind = get_insertion_index(tt)\n",
    "        wt,tt = wt[:iind] + str_wt + wt[iind:], tt[:iind] + str_tt + tt[iind:]\n",
    "    elif r < 0.65:\n",
    "        # Just swap positions of two address terms\n",
    "        swappable_inds = [i for i in range(len(wt)) if not (tt[i][:3] == \"str\" or tt[i] == \"unit\" or tt[i] == \"pobox\")]\n",
    "        if len(swappable_inds) > 2:\n",
    "            i, j = rand.sample(swappable_inds, 2)\n",
    "            wt[i], wt[j] = wt[j], wt[i]\n",
    "            tt[i], tt[j] = tt[j], tt[i]\n",
    "    elif r < 0.8 and \"postal_code\" in tt:\n",
    "        # Just move location of postal code\n",
    "        i = tt.index(\"postal_code\")\n",
    "        swappable_inds = [i for i in range(len(wt)) if tt[i][:3] != \"str\"]\n",
    "        if len(swappable_inds) > 1:\n",
    "            j = rand.choice(swappable_inds)\n",
    "            wt[i], wt[j] = wt[j], wt[i]\n",
    "            tt[i], tt[j] = tt[j], tt[i]\n",
    "\n",
    "\n",
    "    new_wt, new_tt = [], []\n",
    "\n",
    "    # Iterate overall address terms. For each term add the standardized term to std_words and a non_standard equiv or abbrev to nstd_words\n",
    "    # We also drop address terms with a probability so the standardizer can learn to standardize incomplete addresses\n",
    "    keep_street = prob(0.99) \n",
    "\n",
    "    # Learn to also parse addresses with duplicate terms (streetnames, city names)\n",
    "    pot_dup_words, pot_dup_tags = [], []\n",
    "\n",
    "    # Chance we also move the unit term to the street_no term so 165-43 abc street\n",
    "    nstsno = None\n",
    "    for i in range(len(wt)):\n",
    "        if tt[i] == \"Municipality\":\n",
    "            new_wt.append(wt[i])\n",
    "            new_tt.append(tt[i])\n",
    "            if prob(0.8):\n",
    "                pot_dup_words.append(wt[i])\n",
    "                pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"PostalCode\":\n",
    "            pc = wt[i].replace(\" \", \"\")\n",
    "            if len(pc) < 6 or prob(0.2):\n",
    "                continue\n",
    "            else:\n",
    "                if wt[i][3] != \" \" and len(wt[i])==6:\n",
    "                    wt[i] = wt[i][:3] + \" \" + wt[i][3:]\n",
    "                wt[i] = choice([wt[i], pc[:3], pc[3:]], p=[0.94, 0.02, 0.02])\n",
    "                new_wt.append(wt[i])\n",
    "                new_tt.append(tt[i])\n",
    "                if prob(0.8):\n",
    "                    pot_dup_words.append(wt[i])\n",
    "                    pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"Province\":\n",
    "            nst = wt[i] if wt[i] not in to_non_stand_prov or prob(0.6) else rand.choice(to_non_stand_prov[wt[i]])\n",
    "            new_wt.append(nst)\n",
    "            new_tt.append(tt[i])\n",
    "            if prob(0.6):\n",
    "                pot_dup_words.append(nst)\n",
    "                pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"Country\":\n",
    "            nst = wt[i] if prob(0.7) else \"canada\"\n",
    "            new_wt.append(nst)\n",
    "            new_tt.append(tt[i])\n",
    "            if prob(0.6):\n",
    "                pot_dup_words.append(nst)\n",
    "                pot_dup_tags.append(tt[i])\n",
    "        elif tt[i] == \"RuralRoad\":\n",
    "            new_wt.append(wt[i])\n",
    "            new_tt.append(tt[i])\n",
    "        elif tt[i] == \"PoBox\":\n",
    "            unit_sep = rand.choice([\"#\", \"# \", \" #\", \" # \", \"\", \" \", \" \", \" \"])\n",
    "            new_wt.append(rand.choice([f\"po box{unit_sep}{wt[i]} \", f\"{rand.choice(to_non_stand_num_term[\"po box\"])}{unit_sep}{wt[i]}\"]))\n",
    "            new_tt.append(tt[i])\n",
    "\n",
    "        # The following terms must all be dropped or none are dropped\n",
    "        if keep_street:\n",
    "            if tt[i] == \"Unit\":\n",
    "                unit_sep = rand.choice([\"#\", \"# \", \" #\", \" # \", \"\", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \"])\n",
    "                new_wt.append(choice([f\"unit{unit_sep}{wt[i]}\", f\"{unit_sep}{wt[i]}\".strip(), f\"{rand.choice(to_non_stand_num_term[\"unit\"])}{unit_sep}{wt[i]}\"], p=[0.2, 0.5, 0.3]))\n",
    "                new_tt.append(tt[i])\n",
    "            elif tt[i] == \"ph\":\n",
    "                unit_sep = rand.choice([\"#\", \"# \", \" #\", \" # \", \"\", \"\", \" \", \" \", \" \"])\n",
    "                new_wt.append(rand.choice([f\"ph {unit_sep}{wt[i]} \", f\"{rand.choice(to_non_stand_num_term[\"ph\"])}{unit_sep}{wt[i]}\"]))\n",
    "                new_tt.append(\"Unit\")\n",
    "            elif tt[i] == \"StreetNumber\":\n",
    "                new_wt.append(wt[i])\n",
    "                new_tt.append(tt[i])\n",
    "            elif tt[i] == \"StreetName\":\n",
    "                sst = \" \".join([w if w not in to_std else to_std[w] for w in wt[i].split()])\n",
    "                nst = \" \".join([w if w not in to_non_std or prob(0.7) else rand.choice(to_non_std[w]) for w in sst.split()])\n",
    "                new_wt.append(nst)\n",
    "                new_tt.append(tt[i])\n",
    "                if prob(0.8):\n",
    "                    pot_dup_words.append(nst)\n",
    "                    pot_dup_tags.append(tt[i])\n",
    "    \n",
    "    if prob(0.03):\n",
    "        new_wt.extend(pot_dup_words)\n",
    "        new_tt.extend(pot_dup_tags)\n",
    "\n",
    "    wt,tt = new_wt, new_tt\n",
    "    # Apply OCR augmentation to address\n",
    "    if prob(0.2): \n",
    "        words_new, tags_new = [], []\n",
    "        for i in range(len(wt)):\n",
    "            augword = wt[i]\n",
    "            if (tt[i] == \"postal_code\"):\n",
    "                augword = pc_augment(augword, letter_aug= 0.9, num_aug= 0.8)\n",
    "            elif (tt[i] != \"unit\" and tt[i]!=\"pobox\" and tt[i]!=\"street_no\" and prob(0.3)):\n",
    "                augword = augment(augword)\n",
    "            elif (tt[i] == \"unit\" or tt[i] ==\"pobox\" or tt[i]==\"street_no\" and prob(0.03)):\n",
    "                augword = num_augment(augword)\n",
    "            if (tt[i] != \"unit\" and tt[i]!=\"pobox\" and tt[i]!=\"street_no\" and prob(0.02)):\n",
    "                augword = aug_split.augment(augword)[0]\n",
    "            \n",
    "            tags_new.extend([tt[i]] * len(augword.split()))\n",
    "            words_new.extend(augword.split())                \n",
    "        wt, tt = words_new, tags_new\n",
    "\n",
    "    res_wt, res_tt = [],[]\n",
    "    for i in range(len(wt)):\n",
    "        res_wt.extend(wt[i].split())\n",
    "        res_tt.extend([tt[i]]*len(tt[i].split()))\n",
    "\n",
    "    return res_wt, res_tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Load data from spreadsheets and perform data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:21: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  cpcdf = pd.read_csv(\"data\\CanadianPostalCodes202312.csv\")\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:32: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  city_df = pd.read_csv(\"data\\cgn_canada_csv_eng.csv\")\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (2,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (2,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (2,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (2,8,9,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (7,8,9,10,15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:5: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
      "C:\\Users\\ericd\\AppData\\Local\\Temp\\ipykernel_14828\\729816753.py:32: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  city_df = pd.read_csv(\"data\\cgn_canada_csv_eng.csv\")\n"
     ]
    }
   ],
   "source": [
    "statcan_data = []\n",
    "statcan_relevant_cols = [\"street_no\", \"street\", \"city\", \"postal_code\", \"Province\"]\n",
    "dtypes = {key: str for key in statcan_relevant_cols}\n",
    "for prov in province_lst: \n",
    "    df = pd.read_csv(f\"data\\ODA_{prov.capitalize()}_v1.csv\", dtype=dtypes).drop_duplicates(subset=[\"full_addr\"])\n",
    "    df[\"Province\"] = prov\n",
    "    df = df[(df[\"street\"] != \"UNASSIGNED\")& (df[\"postal_code\"] != \"UNASSIGNED\")& (df[\"street_no\"].str.contains(\"-\") == False)]\n",
    "    df = df.dropna(subset  = [\"str_name\"])\n",
    "    df = df.drop(df[df[\"postal_code\"].isnull()].sample(frac=0.75).index)\n",
    "    statcan_data.append(df)\n",
    "\n",
    "\n",
    "statcan_df = pd.concat(statcan_data, ignore_index=True)\n",
    "statcan_df.rename(columns={\"unit\" : \"Unit\", \"street_no\" : \"StreetNumber\", \"street\": \"StreetName\", \"postal_code\": \"PostalCode\", \"city\": \"Municipality\"}, inplace=True)\n",
    "statcan_df[\"PoBox\"] = \"\"\n",
    "statcan_df[\"RuralRoad\"] = \"\"\n",
    "statcan_df[\"Address\"] = \"\"\n",
    "statcan_df[\"Tags\"] = \"\"\n",
    "statcan_df.head()\n",
    "\n",
    "cpcdf = pd.read_csv(\"data\\CanadianPostalCodes202312.csv\")\n",
    "cpcdf = cpcdf[[\"POSTAL_CODE\", \"CITY\", \"PROVINCE_ABBR\"]]\n",
    "cpcdf.rename(columns={\"POSTAL_CODE\": \"PostalCode\", \"CITY\": \"Municipality\", \"PROVINCE_ABBR\": \"Province\"}, inplace=True)\n",
    "cpcdf[\"Unit\"] = \"\"\n",
    "cpcdf[\"PoBox\"] = \"\"\n",
    "cpcdf[\"StreetNumber\"] = \"\"\n",
    "cpcdf[\"StreetName\"] = \"\"\n",
    "cpcdf[\"StreetName\"] = \"\" \n",
    "cpcdf[\"Address\"] = \"\"\n",
    "cpcdf[\"Tags\"] = \"\"\n",
    "\n",
    "city_df = pd.read_csv(\"data\\cgn_canada_csv_eng.csv\")\n",
    "city_df = city_df[(city_df['Generic Category']== \"Populated Place\") & (city_df['Language']== \"Undetermined\")].drop_duplicates(subset=['Geographical Name'])\n",
    "city_df['Address'] = city_df['Geographical Name'].apply(lambda city : city.lower())\n",
    "city_df['Tags']=city_df['Address'].apply(lambda city : [\"Municipality\"]*len(city.split()))\n",
    "city_df = city_df[['Address', 'Tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 148249/1583771 [00:57<14:08, 1692.00it/s]"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(statcan_df.iterrows(), total=statcan_df.shape[0]):\n",
    "    wt, tt = [], []\n",
    "    illegal_pc = [\"VACANT\", \"QUEENS\", \"RMC\", \"na\", \"UNKNOWN\", \"UNASSIGNED\"]\n",
    "    \n",
    "    if prob(0.3):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"Unit\")\n",
    "    elif prob(0.4):\n",
    "        wt.append(choice([f\"{rand.randint(1,9999)}\", f\"{rand.randint(1,99999)}\"], p= [0.8, 0.2]))\n",
    "        tt.append(\"PoBox\")\n",
    "    elif prob(0.1):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"ph\")\n",
    "\n",
    "    row[\"RuralRoad\"] = rand_rr() if prob(0.05) else \"\"\n",
    "    row[\"PostalCode\"] = row[\"PostalCode\"] if row[\"PostalCode\"] not in illegal_pc else \"\"\n",
    "\n",
    "    for tag in [\"StreetNumber\", \"StreetName\", \"RuralRoad\", \"Municipality\", \"Province\"]:\n",
    "        if isinstance(row[tag], str) and not row[tag].isspace() and not row[tag] == \"\":\n",
    "            tt.append(tag)\n",
    "            wt.append(row[tag].lower())\n",
    "\n",
    "    if prob(0.4):\n",
    "        wt.append(\"ca\")\n",
    "        tt.append(\"Country\")\n",
    "\n",
    "    wt,tt = gen_parsed_tags(wt, tt, is_en=row[\"Province\"].lower() != \"qc\")\n",
    "    statcan_df.at[i, \"Address\"] = \" \".join(wt)\n",
    "    statcan_df.at[i, \"Tags\"] = f\"{tt}\"\n",
    "\n",
    "statcan_df = statcan_df[[\"Address\", \"Tags\"]]\n",
    "statcan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pb#7193 6125 david ports rr 5 pembroke ontario...</td>\n",
       "      <td>['PoBox', 'StreetNumber', 'StreetName', 'Stree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9366 blvd bolduc jonquiere g8a 1y9 qc</td>\n",
       "      <td>['StreetNumber', 'StreetName', 'StreetName', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca nl a2h lb8 ste# 5437b 6652 gamble groves co...</td>\n",
       "      <td>['Country', 'Province', 'PostalCode', 'PostalC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9250 anderson mtns athabasca t9s 1n3</td>\n",
       "      <td>['StreetNumber', 'StreetName', 'StreetName', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8848 smith divide grande prairie alberta</td>\n",
       "      <td>['StreetNumber', 'StreetName', 'StreetName', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Address  \\\n",
       "0  pb#7193 6125 david ports rr 5 pembroke ontario...   \n",
       "1              9366 blvd bolduc jonquiere g8a 1y9 qc   \n",
       "2  ca nl a2h lb8 ste# 5437b 6652 gamble groves co...   \n",
       "3               9250 anderson mtns athabasca t9s 1n3   \n",
       "4           8848 smith divide grande prairie alberta   \n",
       "\n",
       "                                                Tags  \n",
       "0  ['PoBox', 'StreetNumber', 'StreetName', 'Stree...  \n",
       "1  ['StreetNumber', 'StreetName', 'StreetName', '...  \n",
       "2  ['Country', 'Province', 'PostalCode', 'PostalC...  \n",
       "3  ['StreetNumber', 'StreetName', 'StreetName', '...  \n",
       "4  ['StreetNumber', 'StreetName', 'StreetName', '...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in tqdm(cpcdf.iterrows(), total=cpcdf.shape[0]):\n",
    "    wt, tt = [], []\n",
    "    \n",
    "    if row[\"Province\"].lower() != \"qc\":\n",
    "        row[\"StreetName\"] = fake_en.street_name().lower() if prob(0.995) else rand_ordinal_street()\n",
    "        if prob(0.05):\n",
    "            row[\"StreetName\"] += \" \" + rand.choice(street_dir_en)\n",
    "    if row[\"Province\"].lower() == \"qc\":\n",
    "        row[\"StreetName\"]= fake_fr.street_name().lower() if prob(0.995) else rand_ordinal_street() \n",
    "        if prob(0.05):\n",
    "            row[\"StreetName\"] += \" \" + rand.choice(street_dir_fr)\n",
    "    \n",
    "    row[\"StreetNumber\"] = f\"{rand.randint(1,9999)}\" if prob(0.95) else \"\"\n",
    "    row[\"RuralRoad\"] = rand_rr() if prob(0.05) else \"\"\n",
    "\n",
    "    if prob(0.2):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"Unit\")\n",
    "    elif prob(0.3):\n",
    "        wt.append(choice([f\"{rand.randint(1,9999)}\", f\"{rand.randint(1,99999)}\"], p= [0.8, 0.2]))\n",
    "        tt.append(\"PoBox\")\n",
    "    elif prob(0.1):\n",
    "        wt.append(rand_unit_num())\n",
    "        tt.append(\"ph\")\n",
    "    \n",
    "    rel_tags = [\"StreetNumber\", \"StreetName\", \"RuralRoad\", \"Municipality\", \"PostalCode\", \"Province\"]\n",
    "    for tag in rel_tags:\n",
    "        if isinstance(row[tag], str) and not row[tag].isspace() and not row[tag] == \"\":\n",
    "            tt.append(tag)\n",
    "            wt.append(row[tag].lower())\n",
    "\n",
    "    if prob(0.3):\n",
    "        wt.append(\"ca\")\n",
    "        tt.append(\"Country\")\n",
    "\n",
    "    wt,tt = gen_parsed_tags(wt, tt, is_en=row[\"Province\"].lower() != \"qc\")\n",
    "    cpcdf.at[i, \"Address\"] = \" \".join(wt)\n",
    "    cpcdf.at[i, \"Tags\"] = f\"{tt}\"\n",
    "\n",
    "cpcdf = cpcdf[[\"Address\", \"Tags\"]]\n",
    "cpcdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some lesser seen postal codes which are sometimes incorrectly standardized. We generate 1000 addresses for each of these postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "pc_city_map = {\n",
    "    \"P0B 1A0\": \"Baysville\",\n",
    "    \"P0B 1E0\": \"Milford Bay\",\n",
    "    \"P0B 1G0\": \"Minett\",\n",
    "    \"P0B 1J0\": \"Port Carling\",\n",
    "    \"P0B 1K0\": \"Port Sandfield\",\n",
    "    \"P0B 1L0\": \"Port Sydney\",\n",
    "    \"P0B 1M0\": \"Utterson\",\n",
    "    \"P0B 1P0\": \"Windermere\",\n",
    "    \"P0H 1A0\": \"Arnstein\",\n",
    "    \"P0H 1B0\": \"Astorville\",\n",
    "    \"P0H 1C0\": \"Bear Island\",\n",
    "    \"P0H 1E0\": \"Bonfield\",\n",
    "    \"P0H 1G0\": \"Cache Bay\",\n",
    "    \"P0H 1H0\": \"Callander\",\n",
    "    \"P0H 1J0\": \"Commanda\",\n",
    "    \"P0H 1K0\": \"Corbeil\",\n",
    "    \"P0H 1L0\": \"Crystal Falls\",\n",
    "    \"P0H 1M0\": \"Field\",\n",
    "    \"P0H 1N0\": \"Golden Valley\",\n",
    "    \"P0H 1P0\": \"Hornell Heights\",\n",
    "    \"P0H 1R0\": \"Lavigne\",\n",
    "    \"P0H 1S0\": \"Loring\",\n",
    "    \"P0H 1T0\": \"Marten River\",\n",
    "    \"P0H 1V0\": \"Mattawa\",\n",
    "    \"P0H 1W0\": \"Nipissing\",\n",
    "    \"P0H 1Y0\": \"Port Loring\",\n",
    "    \"P0H 1Z0\": \"Powassan\",\n",
    "    \"P0H 2A0\": \"Redbridge\",\n",
    "    \"P0H 2C0\": \"River Valley\",\n",
    "    \"P0H 2E0\": \"Rutherglen\",\n",
    "    \"P0H 2H0\": \"Temagami\",\n",
    "    \"P0H 2J0\": \"Thorne\",\n",
    "    \"P0H 2K0\": \"Tilden Lake\",\n",
    "    \"P0H 2L0\": \"Trout Creek\",\n",
    "    \"P0H 2M0\": \"Verner\",\n",
    "    \"P0H 2N0\": \"Warren\",\n",
    "    \"P0H 2R0\": \"Restoule\",\n",
    "    \"V0N 1A0\":\" Alert Bay\",\n",
    "    \"V0N 1B0\":\" Whistler\",\n",
    "    \"V0N 1E0\":\" Blubber Bay\",\n",
    "    \"V0N 1G0\":\" Bowen Island\",\n",
    "    \"V0N 1H0\":\" Brackendale\",\n",
    "    \"V0N 1J0\":\" Britannia Beach\",\n",
    "    \"V0N 1K0\":\" Coal Harbour\",\n",
    "    \"V0N 1L0\":\" D'Arcy\",\n",
    "    \"V0N 1M0\":\" Dawsons Landing\",\n",
    "    \"V0N 1N0\":\" Egmont\",\n",
    "    \"V0N 1P0\":\" Galiano Island\",\n",
    "    \"V0N 1S0\":\" Garden Bay\",\n",
    "    \"V0N 1T0\":\" Garibaldi Highlands\",\n",
    "    \"V0N 1V0\":\" Gibsons\",\n",
    "    \"V0N 1W0\":\" Gillies Bay\",\n",
    "    \"V0N 1Z0\":\" Holberg\",\n",
    "    \"V0N 2B0\":\" Kingcome Inlet\",\n",
    "    \"V0N 2E0\":\" Lions Bay\",\n",
    "    \"V0N 2G0\":\" Lund\",\n",
    "    \"V0N 2H0\":\" Madeira Park\",\n",
    "    \"V0N 2H1\":\" Pender Harbour\",\n",
    "    \"V0N 2J0\":\" Mayne Island\",\n",
    "    \"V0N 2K0\":\" Mount Currie\",\n",
    "    \"V0N 2L0\":\" Pemberton\",\n",
    "    \"V0N 2M0\":\" Pender Island\",\n",
    "    \"V0N 2N0\":\" Port Alice\",\n",
    "    \"V0N 2P0\":\" Port Hardy\",\n",
    "    \"V0N 2R0\":\" Port McNeill\",\n",
    "    \"V0N 2S0\":\" Port Mellon\",\n",
    "    \"V0N 2V0\":\" Quatsino\",\n",
    "    \"V0N 2W0\":\" Roberts Creek\",\n",
    "    \"V0N 2Y0\":\" Saturna\",\n",
    "    \"V0N 3A0\":\" Sechelt\",\n",
    "    \"V0N 3B0\":\" Seton Portage\",\n",
    "    \"V0N 3C0\":\" Shalalth\",\n",
    "    \"V0N 3E0\":\" Sointula\",\n",
    "    \"V0N 3J0\":\" Telegraph Cove\",\n",
    "    \"V0N 3K0\":\" Van Anda\",\n",
    "    \"V0N 3L0\":\" Winter Harbour\",\n",
    "    \"V0N 3P0\":\" Woss\",\n",
    "    \"V0N 3V0\":\" Gibsons\",\n",
    "    \"V0N 3Z0\":\" Furry Creek\",\n",
    "    \"V0R 1A0\":\" Ahousat\",\n",
    "    \"V0R 1B0\":\" Bamfield\",\n",
    "    \"V0R 1G0\":\" Bowser\",\n",
    "    \"V0R 1H0\":\" Cassidy\",\n",
    "    \"V0R 1K0\":\" Chemainus\",\n",
    "    \"V0R 1L0\":\" Cobble Hill\",\n",
    "    \"V0R 1M0\":\" Coombs\",\n",
    "    \"V0R 1N0\":\" Cowichan Bay\",\n",
    "    \"V0R 1R0\":\" Crofton\",\n",
    "    \"V0R 1S0\":\" Cumberland\",\n",
    "    \"V0R 1T0\":\" Denman Island\",\n",
    "    \"V0R 1V0\":\" Errington\",\n",
    "    \"V0R 1W0\":\" Fanny Bay\",\n",
    "    \"V0R 1X0\":\" Gabriola\",\n",
    "    \"V0R 1Y0\":\" Honeymoon Bay\",\n",
    "    \"V0R 1Z0\":\" Hornby Island\",\n",
    "    \"V0R 2B0\":\" Kildonan\",\n",
    "    \"V0R 2C0\":\" Koksilah\",\n",
    "    \"V0R 2G0\":\" Lake Cowichan\",\n",
    "    \"V0R 2H0\":\" Lantzville\",\n",
    "    \"V0R 2J0\":\" Lasqueti\",\n",
    "    \"V0R 2K0\":\" Lazo\",\n",
    "    \"V0R 2L0\":\" Malahat\",\n",
    "    \"V0R 2M0\":\" Merville\",\n",
    "    \"V0R 2N0\":\" Mesachie Lake\",\n",
    "    \"V0R 2P0\":\" Mill Bay\",\n",
    "    \"V0R 2V0\":\" Royston\",\n",
    "    \"V0R 2W0\":\" Shawnigan Lake\",\n",
    "    \"V0R 2Y0\":\" Thetis Island\",\n",
    "    \"V0R 2Z0\":\" Tofino\",\n",
    "    \"V0R 3A0\":\" Ucluelet\",\n",
    "    \"V0R 3B0\":\" Union Bay\",\n",
    "    \"V0R 3C0\":\" Westholme\",\n",
    "    \"V0R 3E1\":\" Youbou\",\n",
    "    \"V0R 4K0\":\" Chemainus\",\n",
    "    \"V0R 5K0\":\" Penelakut Island\",\n",
    "    \"L0N 1A0\":\" Alton\",\n",
    "    \"L0N 1B0\":\" Belfountain\",\n",
    "    \"L0N 1C0\":\" Caledon Village\",\n",
    "    \"L0N 1E0\":\" Caledon East\",\n",
    "    \"L0N 1G0\":\" Grand Valley\",\n",
    "    \"L0N 1H0\":\" Honeywood\",\n",
    "    \"L0N 1J0\":\" Horning's Mills\",\n",
    "    \"L0N 1K0\":\" Inglewood\",\n",
    "    \"L0N 1L0\":\" Laurel\",\n",
    "    \"L0N 1M0\":\" Mansfield\",\n",
    "    \"L0N 1N0\":\" Orton\",\n",
    "    \"L0N 1P0\":\" Palgrave\",\n",
    "    \"L0N 1R0\":\" Rosemont\",\n",
    "    \"L0N 1S0\":\" Shelburne\",\n",
    "    \"N0N 1A0\":\" Alvinston\",\n",
    "    \"N0N 1B0\":\" Brigden\",\n",
    "    \"N0N 1C0\":\" BrightΓÇÖs Grove\",\n",
    "    \"N0N 1E0\":\" Camlachie\",\n",
    "    \"N0N 1G0\":\" Corunna\",\n",
    "    \"N0N 1H0\":\" Courtright\",\n",
    "    \"N0N 1J0\":\" Forest\",\n",
    "    \"N0N 1K0\":\" Inwood\",\n",
    "    \"N0N 1M0\":\" Mooretown\",\n",
    "    \"N0N 1N0\":\" Oil City\",\n",
    "    \"N0N 1P0\":\" Oil Springs\",\n",
    "    \"N0N 1R0\":\" Petrolia\",\n",
    "    \"N0N 1T0\":\" Wyoming\",\n",
    "    \"A0N 1A0\":\" Aguathuna\",\n",
    "    \"A0N 1B0\":\" Barachois Brook\",\n",
    "    \"A0N 1C0\":\" Cape Ray\",\n",
    "    \"A0N 1E0\":\" Cape St. George\",\n",
    "    \"A0N 1G0\":\" Cartyville\",\n",
    "    \"A0N 1H0\":\" Codroy\",\n",
    "    \"A0N 1J0\":\" Doyles\",\n",
    "    \"A0N 1K0\":\" Grand Bay East\",\n",
    "    \"A0N 1M0\":\" Heatherton\",\n",
    "    \"A0N 1N0\":\" Highlands\",\n",
    "    \"A0N 1P0\":\" Jeffrey's\",\n",
    "    \"A0N 1R0\":\" Lourdes\",\n",
    "    \"A0N 1S0\":\" Noels Pond\",\n",
    "    \"A0N 1T0\":\" Port au Port\",\n",
    "    \"A0N 1V0\":\" Robinsons\",\n",
    "    \"A0N 1W0\":\" St. Andrew's\",\n",
    "    \"A0N 1X0\":\" St. David's\",\n",
    "    \"A0N 1Y0\":\" St. Fintan's\",\n",
    "    \"A0N 1Z0\":\" St. George's\",\n",
    "    \"A0N 2B0\":\" South Branch\",\n",
    "    \"A0N 2C0\":\" Stephenville Crossing\",\n",
    "    \"A0N 2E0\":\" West Bay Centre\",\n",
    "    \"A0N 2G0\":\" Black Duck Siding\",\n",
    "    \"A0N 2H0\":\" Burgeo\",\n",
    "    \"A0N 2J0\":\" Ramea\",\n",
    "    \"A0N 2K0\":\" Fran├ºois\",\n",
    "    \"A0N 2L0\":\" Grey River\",\n",
    "    \"B0N 1C0\":\" Brookfield\",\n",
    "    \"B0N 1E0\":\" Centre Burlington\",\n",
    "    \"B0N 1G0\":\" Cheverie\",\n",
    "    \"B0N 1H0\":\" Curry's Corner\",\n",
    "    \"B0N 1J0\":\" Densmore Mills\",\n",
    "    \"B0N 1K0\":\" Elderbank\",\n",
    "    \"B0N 1L0\":\" Ellershouse\",\n",
    "    \"B0N 1P0\":\" Kennetcook\",\n",
    "    \"B0N 1T0\":\" Maitland\",\n",
    "    \"B0N 1V0\":\" Meaghers Grant\",\n",
    "    \"B0N 1W0\":\" Micmac\",\n",
    "    \"B0N 1X0\":\" Middle Musquodoboit\",\n",
    "    \"B0N 1Y0\":\" Milford Station, Milford\",\n",
    "    \"B0N 1Z0\":\" Mount Uniacke\",\n",
    "    \"B0N 2A0\":\" Newport\",\n",
    "    \"B0N 2B0\":\" Newport Station\",\n",
    "    \"B0N 2C0\":\" Noel\",\n",
    "    \"B0N 2E0\":\" Ste-Croix\",\n",
    "    \"B0N 2G0\":\" Scotch Village\",\n",
    "    \"B0N 2H0\":\" Shubenacadie\",\n",
    "    \"B0N 2J0\":\" Stewiacke\",\n",
    "    \"B0N 2K0\":\" Summerville\",\n",
    "    \"B0N 2L0\":\" Upper Kennetcook\",\n",
    "    \"B0N 2M0\":\" Upper Musquodoboit\",\n",
    "    \"B0N 2N0\":\" Upper Rawdon\",\n",
    "    \"B0N 2P0\":\" Upper Stewiacke\",\n",
    "    \"B0N 2R0\":\" Walton\",\n",
    "    \"B0N 2T0\":\" Windsor\",\n",
    "    \"B0N 3A0\":\" Ellershouse\",\n",
    "    \"G0N 1B0\":\" Saint-Joseph-de-Coleraine, Saint-Julien\",\n",
    "    \"G0N 1C0\":\" Sainte-Clotilde-de-Beauce\",\n",
    "    \"G0N 1E0\":\" Disraeli\",\n",
    "    \"G0N 1E1\":\" Sainte-Prax├¿de\",\n",
    "    \"G0N 1E2\":\" Saint-Jacques-le-Majeur-de-Wolfestown\",\n",
    "    \"G0N 1G0\":\" Sacr├⌐-C┼ôur-de-J├⌐sus\",\n",
    "    \"G0N 1H0\":\" East Broughton\",\n",
    "    \"G0N 1J0\":\" Saint-Jacques-de-Leeds\",\n",
    "    \"G0N 1K0\":\" Kinnear's Mills\",\n",
    "    \"G0N 1M0\":\" Saint-Adrien-d'Irlande\",\n",
    "    \"G0N 1N0\":\" Saint-Ferdinand\",\n",
    "    \"G0N 1P0\":\" Saint-Fr├⌐d├⌐ric\",\n",
    "    \"G0N 1R0\":\" Saint-Jules\",\n",
    "    \"G0N 1S0\":\" Adstock\",\n",
    "    \"G0N 1T0\":\" Saint-Pierre-de-Broughton\",\n",
    "    \"G0N 1V0\":\" Saint-S├⌐verin\",\n",
    "    \"G0N 1X0\":\" Tring-Jonction\",\n",
    "    \"S0N 0A0\":\" Abbey\",\n",
    "    \"S0N 0B0\":\" Admiral\",\n",
    "    \"S0N 0C0\":\" Aneroid\",\n",
    "    \"S0N 0E0\":\" Blumenhof\",\n",
    "    \"S0N 0G0\":\" Bracken\",\n",
    "    \"S0N 0H0\":\" Burstall\",\n",
    "    \"S0N 0J0\":\" Cabri\",\n",
    "    \"S0N 0K0\":\" Cadillac\",\n",
    "    \"S0N 0M0\":\" Claydon\",\n",
    "    \"S0N 0N0\":\" Climax\",\n",
    "    \"S0N 0P0\":\" Consul\",\n",
    "    \"S0N 0S0\":\" Dollard\",\n",
    "    \"S0N 0T0\":\" Eastend\",\n",
    "    \"S0N 0V0\":\" Fox Valley\",\n",
    "    \"S0N 0W0\":\" Frontier\",\n",
    "    \"S0N 0X0\":\" Glenbain\",\n",
    "    \"S0N 0Y0\":\" Golden Prairie\",\n",
    "    \"S0N 1A0\":\" Gull Lake\",\n",
    "    \"S0N 1C0\":\" Hazenmore\",\n",
    "    \"S0N 1E0\":\" Hazlet\",\n",
    "    \"S0N 1G0\":\" Lancer\",\n",
    "    \"S0N 1H0\":\" Leader\",\n",
    "    \"S0N 1L0\":\" Liebenthal\",\n",
    "    \"S0N 1M0\":\" McMahon\",\n",
    "    \"S0N 1N0\":\" Maple Creek\",\n",
    "    \"S0N 1P0\":\" Mendham\",\n",
    "    \"S0N 1S0\":\" Neidpath\",\n",
    "    \"S0N 1T0\":\" Neville\",\n",
    "    \"S0N 1V0\":\" Orkney\",\n",
    "    \"S0N 1W0\":\" Pambrun\",\n",
    "    \"S0N 1X0\":\" Pennant Station\",\n",
    "    \"S0N 1Y0\":\" Piapot\",\n",
    "    \"S0N 1Z0\":\" Ponteix\",\n",
    "    \"S0N 2A0\":\" Portreeve\",\n",
    "    \"S0N 2B0\":\" Prelate\",\n",
    "    \"S0N 2E0\":\" Richmound\",\n",
    "    \"S0N 2G0\":\" Robsart\",\n",
    "    \"S0N 2H0\":\" Sceptre\",\n",
    "    \"S0N 2L0\":\" Shackleton\",\n",
    "    \"S0N 2M0\":\" Shaunavon\",\n",
    "    \"S0N 2N0\":\" Simmie\",\n",
    "    \"S0N 2P0\":\" Stewart Valley\",\n",
    "    \"S0N 2R0\":\" Success\",\n",
    "    \"S0N 2S0\":\" Tompkins\",\n",
    "    \"S0N 2T0\":\" Val Marie\",\n",
    "    \"S0N 2V0\":\" Vanguard\",\n",
    "    \"S0N 2W0\":\" Vidora\",\n",
    "    \"S0N 2X0\":\" Webb\",\n",
    "    \"S0N 2Y0\":\" Wymark\",\n",
    "}\n",
    "\n",
    "pc_to_prov = {\n",
    "    \"a\" : \"nl\",\n",
    "    \"b\" : \"ns\",\n",
    "    \"g\" : \"qc\",\n",
    "    \"h\" : \"qc\",\n",
    "    \"j\" : \"qc\",\n",
    "    \"k\" : \"on\",\n",
    "    \"l\" : \"on\",\n",
    "    \"m\" : \"on\",\n",
    "    \"n\" : \"on\",\n",
    "    \"p\" : \"on\",\n",
    "    \"r\" : \"mb\",\n",
    "    \"s\" : \"sk\",\n",
    "    \"t\" : \"ab\",\n",
    "    \"v\" : \"bc\"\n",
    "}\n",
    "\n",
    "addr = []\n",
    "tags = []\n",
    "\n",
    "for k in pc_city_map.keys():\n",
    "    pc = k.lower()\n",
    "    for i in range(1000):\n",
    "        city =  pc_city_map[k].lower()\n",
    "\n",
    "        wt,tt = [], []\n",
    "        \n",
    "        if prob(0.1):\n",
    "            wt.append(rand_unit_num())\n",
    "            tt.append(\"Unit\")\n",
    "        elif prob(0.5):\n",
    "            wt.append(f\"{rand.randint(1,9999)}\")\n",
    "            tt.append(\"PoBox\")\n",
    "\n",
    "        wt.append(f\"{rand.randint(1,9999)}\")\n",
    "        tt.append(\"StreetNumber\")\n",
    "\n",
    "        if prob(0.995):\n",
    "            sn = fake_en.street_name().lower()\n",
    "            wt.append(sn)\n",
    "            tt.append(\"StreetName\")\n",
    "        else:\n",
    "            wt.append(rand_ordinal_street())\n",
    "            tt.append(\"StreetName\")\n",
    "\n",
    "        wt.append(city)\n",
    "        tt.append(\"Municipality\")\n",
    "\n",
    "        wt.append(pc)\n",
    "        tt.append(\"PostalCode\")\n",
    "\n",
    "        wt.append(pc_to_prov[pc[0]])\n",
    "        tt.append(\"Province\")\n",
    "        \n",
    "        if prob(0.4):\n",
    "            wt.append(\"ca\")\n",
    "            tt.append(\"Country\")\n",
    "        \n",
    "        wt,tt = gen_parsed_tags(wt, tt, is_en=pc_to_prov[pc[0]] != \"qc\")\n",
    "                                \n",
    "        addr.append(\" \".join(wt))\n",
    "        tags.append(f\"{tt}\")\n",
    "\n",
    "popc_df = pd.DataFrame({\"Address\": addr, \"Tags\": tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([statcan_df, cpcdf, city_df, popc_df], ignore_index=True)\n",
    "all_df = all_df[all_df['Address'].str.len() > 0]\n",
    "all_df.to_csv('deepparse_train_1.csv', index=False)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
